{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeChastain84/Mike_INFO5731_Fall2024/blob/main/Chastain_Mike_Assignment_02_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Tuesday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (40 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from G2 or Capterra.\n",
        "\n",
        "(4) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the Densho Digital Repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDyTKYs-yGit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278c5311-49b1-40a0-d7d5-5920a9666274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Scraping Page 1 ***\n",
            "*** Scraping Page 2 ***\n",
            "*** Scraping Page 3 ***\n",
            "*** Scraping Page 4 ***\n",
            "*** Scraping Page 5 ***\n",
            "*** Scraping Page 6 ***\n",
            "*** Scraping Page 7 ***\n",
            "*** Scraping Page 8 ***\n",
            "*** Scraping Page 9 ***\n",
            "*** Scraping Page 10 ***\n",
            "*** Scraping Page 11 ***\n",
            "*** Scraping Page 12 ***\n",
            "*** Scraping Page 13 ***\n",
            "*** Scraping Page 14 ***\n",
            "*** Scraping Page 15 ***\n",
            "*** Scraping Page 16 ***\n",
            "*** Scraping Page 17 ***\n",
            "*** Scraping Page 18 ***\n",
            "*** Scraping Page 19 ***\n",
            "*** Scraping Page 20 ***\n",
            "*** Scraping Page 21 ***\n",
            "*** Scraping Page 22 ***\n",
            "*** Scraping Page 23 ***\n",
            "*** Scraping Page 24 ***\n",
            "*** Scraping Page 25 ***\n",
            "*** Scraping Page 26 ***\n",
            "*** Scraping Page 27 ***\n",
            "*** Scraping Page 28 ***\n",
            "*** Scraping Page 29 ***\n",
            "*** Scraping Page 30 ***\n",
            "*** Scraping Page 31 ***\n",
            "*** Scraping Page 32 ***\n",
            "*** Scraping Page 33 ***\n",
            "*** Scraping Page 34 ***\n",
            "*** Scraping Page 35 ***\n",
            "*** Scraping Page 36 ***\n",
            "*** Scraping Page 37 ***\n",
            "*** Scraping Page 38 ***\n",
            "*** Scraping Page 39 ***\n",
            "*** Scraping Page 40 ***\n",
            "Scraped 995 narrators and saved to narrators.csv\n"
          ]
        }
      ],
      "source": [
        "# \"(5) Collect all the information on the 904 narrators in the Densho Digital Repository.\"\n",
        "\n",
        "# Import libraries and modules as needed\n",
        "from bs4 import BeautifulSoup               # Used to parse HTML content\n",
        "from urllib.request import Request, urlopen # Used to send requests to a webpage and open the URL\n",
        "from urllib.error import HTTPError          # Handles HTTP Errors\n",
        "import pandas as pd                         # Data handling\n",
        "import re\n",
        "\n",
        "narrator_data = []    # Empty list to store narrator data\n",
        "\n",
        "main_url = 'https://ddr.densho.org/narrators/?page={}'  # Main url set to iterate through pages\n",
        "\n",
        "count = 0             # Start count to count narrators\n",
        "\n",
        "# Start by looping through the 40 pages of DDR Narrators:\n",
        "for page_num in range(1,41):    # A loop to iterate through page 1 to 40\n",
        "  try:\n",
        "    #  Opening URL and Parsing with BeautifulSoup:\n",
        "    link1 = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'}) #request URL\n",
        "    url1 = urlopen(link1)     # opens the URL and fetches the content\n",
        "    data1 = url1.read()       # reads the and stores the content to data1\n",
        "    data1_soup = BeautifulSoup(data1, 'html.parser')  # parses through the HTML content so we can find narrator info\n",
        "\n",
        "    print(f\"*** Scraping Page {page_num} ***\")\n",
        "\n",
        "    for narrator_link in data1_soup.find_all('h4'):  # Find all the narrator links by identifying h4\n",
        "                                                     # tags which link to the narrator pages\n",
        "      try:\n",
        "        # Accessing narrator's page:\n",
        "        # Retreives the URL of each narrators detailed page:\n",
        "        link2 = Request(narrator_link.a.get('href'), headers={'User-Agent': 'Mozilla/5.0'})\n",
        "        url2 = urlopen(link2)\n",
        "        data2 = url2.read()\n",
        "        data2_soup = BeautifulSoup(data2, 'html.parser')\n",
        "\n",
        "        # Extract narrator details\n",
        "        # Searches for <div> with the class 'col-sm-8 col-md-8'\n",
        "        narrator = data2_soup.find_all(\"div\", attrs={'class': 'col-sm-8 col-md-8'})[0]\n",
        "        name = narrator.h1.text.strip()   # strips the narrator name\n",
        "        bio = narrator.p.text.strip()     # strips the narrator bio\n",
        "\n",
        "        # Add narrator details to the list\n",
        "        result = {'Narrator_Name': name,\n",
        "                  'Bio': bio\n",
        "                }\n",
        "        narrator_data.append(result)    # Appends the result to the empty narrator list\n",
        "\n",
        "        count += 1\n",
        "\n",
        "      # Error handling:\n",
        "      except Exception as e:\n",
        "        print(f\"Error scraping narrator: {e}\")\n",
        "        continue\n",
        "\n",
        "  # Error handling:\n",
        "  except HTTPError as e:\n",
        "    print(f\"HTTPError on page {page_num}: {e}\")\n",
        "    break\n",
        "\n",
        "df = pd.DataFrame(narrator_data)        # put the list in a dataframe\n",
        "df.to_csv('narrators.csv', index=False) # move to the narrators.csv file\n",
        "\n",
        "print(f\"Scraped {count} narrators and saved to narrators.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "  (import re\n",
        "  \n",
        "  Sample text with numbers:\n",
        "  text = \"There are 123 apples and 45 oranges in the basket.\"\n",
        "\n",
        "  Use re.sub() to remove numbers:\n",
        "  \\d+ finds all numbers, '' replaces them with an empty string\n",
        "  no_numbers = re.sub(r'\\d+', '', text)\n",
        "\n",
        "  Print the results:\n",
        "  print(no_numbers))\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "  (!pip install nltk\n",
        "  import nltk\n",
        "  from nltk.corpus import stopwords\n",
        "  from nltk.tokenize import word_tokenize)\n",
        "\n",
        "(4) Lowercase all texts\n",
        "(lowercased_words = [word.lower() for word in words])\n",
        "\n",
        "(5) Stemming.\n",
        "(Removes common prefixes and suffixes. Sometimes results in invalid words not found in the dictionary such as stemming relational to relat.)\n",
        "\n",
        "(6) Lemmatization. (Reduces words to an existing normalized root word. Always results in a real word.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b4baa7-720d-41fa-d588-f6158491e909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "                                                 Bio\n",
            "0  Nisei female. Born May 9, 1927, in Selleck, Wa...\n",
            "1  Nisei male. Born June 12, 1921, in Seattle, Wa...\n",
            "2  Nisei female. Born October 31, 1925, in Seattl...\n",
            "3  Nisei female. Born July 8, 1928, in Boyle Heig...\n",
            "4  Sansei male. Born March 15, 1950, in Torrance,... \n",
            "1) Remove Noise: \n",
            "                                            Clean_Bio\n",
            "0  Nisei female Born May 9 1927 in Selleck Washin...\n",
            "1  Nisei male Born June 12 1921 in Seattle Washin...\n",
            "2  Nisei female Born October 31 1925 in Seattle W...\n",
            "3  Nisei female Born July 8 1928 in Boyle Heights...\n",
            "4  Sansei male Born March 15 1950 in Torrance Cal...\n",
            "\n",
            "2) Remove Numbers: \n",
            "                                            Non_Numbs\n",
            "0  Nisei female Born May   in Selleck Washington ...\n",
            "1  Nisei male Born June   in Seattle Washington G...\n",
            "2  Nisei female Born October   in Seattle Washing...\n",
            "3  Nisei female Born July   in Boyle Heights Cali...\n",
            "4  Sansei male Born March   in Torrance Californi...\n",
            "\n",
            "3) Remove Stopwords: \n",
            "                                          Non_StpWrds\n",
            "0  Nisei female Born May Selleck Washington Spent...\n",
            "1  Nisei male Born June Seattle Washington Grew a...\n",
            "2  Nisei female Born October Seattle Washington F...\n",
            "3  Nisei female Born July Boyle Heights Californi...\n",
            "4  Sansei male Born March Torrance California Gre...\n",
            "\n",
            "4) Lowercase Text: \n",
            "                                            LwrCs_Txt\n",
            "0  nisei female born may selleck washington spent...\n",
            "1  nisei male born june seattle washington grew a...\n",
            "2  nisei female born october seattle washington f...\n",
            "3  nisei female born july boyle heights californi...\n",
            "4  sansei male born march torrance california gre...\n",
            "\n",
            "5) Stemming: \n",
            "                                             Txt_Stem\n",
            "0  nisei femal born may selleck washington spent ...\n",
            "1  nisei male born june seattl washington grew ar...\n",
            "2  nisei femal born octob seattl washington famil...\n",
            "3  nisei femal born juli boyl height california e...\n",
            "4  sansei male born march torranc california grew...\n",
            "\n",
            "6) Lemmatization: \n",
            "                                             Txt_Lemm\n",
            "0  nisei female born may selleck washington spent...\n",
            "1  nisei male born june seattle washington grew a...\n",
            "2  nisei female born october seattle washington f...\n",
            "3  nisei female born july boyle height california...\n",
            "4  sansei male born march torrance california gre...\n",
            "Cleaned data saved to narrators_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# Write code for each of the sub parts with proper comments.\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# download stopwords for 3) and wordnet for 6)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "\n",
        "# (1) Remove noise, such as special characters and punctuations:\n",
        "\n",
        "df = pd.read_csv('narrators.csv')           # load the narrators.csv file\n",
        "\n",
        "def remove_special_characters(text):        # define function for removing 'noise'\n",
        "  if isinstance(text, str):                 # check if the text is a string\n",
        "    return re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "  else:\n",
        "    return \"\"         # Returns an empty string for non-strings\n",
        "\n",
        "df['Clean_Bio'] = df['Bio'].apply(remove_special_characters)  # apply new function to remove 'noise' from Bio column\n",
        "\n",
        "print(df[['Bio']].head(), \"\\n1) Remove Noise:\", \"\\n\", df[['Clean_Bio']].head())      # Verify the first few rows change correctly\n",
        "\n",
        "\n",
        "# (2) Remove numbers.\n",
        "\n",
        "def remove_numbers(text):                   # define function to remove numbers\n",
        "  return re.sub(r'\\d+', '', text)\n",
        "\n",
        "df['Non_Numbs'] = df['Clean_Bio'].apply(remove_numbers)  # apply new function to remove numbers\n",
        "\n",
        "print(\"\\n2) Remove Numbers:\", \"\\n\", df[['Non_Numbs']].head())\n",
        "\n",
        "\n",
        "# (3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "stop_words = set(stopwords.words('english'))  # Set to english\n",
        "\n",
        "def remove_stopwords(text):                   # define function to remove stopwords\n",
        "  words = word_tokenize(text)\n",
        "  return ' '.join([word for word in words if word.lower() not in stop_words])\n",
        "\n",
        "df['Non_StpWrds'] = df['Non_Numbs'].apply(remove_stopwords)     # apply new function to remove stopwords\n",
        "\n",
        "print(\"\\n3) Remove Stopwords:\", \"\\n\", df[['Non_StpWrds']].head())\n",
        "\n",
        "# (4) Lowercase all texts (lowercased_words = [word.lower() for word in words])\n",
        "\n",
        "def lowercase_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "df['LwrCs_Txt'] = df['Non_StpWrds'].apply(lowercase_text)\n",
        "\n",
        "print(\"\\n4) Lowercase Text:\", \"\\n\", df[['LwrCs_Txt']].head())\n",
        "\n",
        "# (5) Stemming. (Removes common prefixes and suffixes. Sometimes results in invalid words not found in the dictionary such as stemming relational to relat.)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_words(text):\n",
        "    words = word_tokenize(text)\n",
        "    return ' '.join([stemmer.stem(word) for word in words])\n",
        "\n",
        "df['Txt_Stem'] = df['LwrCs_Txt'].apply(stem_words)\n",
        "\n",
        "print(\"\\n5) Stemming:\", \"\\n\", df[['Txt_Stem']].head())\n",
        "\n",
        "# # (6) Lemmatization. (Reduces words to an existing normalized root word. Always results in a real word.)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "df['Txt_Lemm'] = df['LwrCs_Txt'].apply(lemmatize_text)\n",
        "\n",
        "print(\"\\n6) Lemmatization:\", \"\\n\", df[['Txt_Lemm']].head())\n",
        "\n",
        "# Save cleaned data to narrators_cleaned.csv\n",
        "df.to_csv('narrators_cleaned.csv', index=False)\n",
        "print(\"Cleaned data saved to narrators_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88a5c4cf-f5cb-4b88-caea-30b7233bc39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "POS Tagging Results:\n",
            "   Nouns  Verbs  Adjectives  Adverbs  \\\n",
            "0     25      8           5        2   \n",
            "1     31     16          16        3   \n",
            "2     26      9           9        1   \n",
            "3     24     10           7        3   \n",
            "4     22      8          11        2   \n",
            "\n",
            "                                          POS_Tagged  \n",
            "0  [(nisei, JJ), (female, NN), (born, NN), (may, ...  \n",
            "1  [(nisei, JJ), (male, NN), (born, VBN), (june, ...  \n",
            "2  [(nisei, JJ), (female, NN), (born, VBN), (octo...  \n",
            "3  [(nisei, JJ), (female, NN), (born, VBN), (july...  \n",
            "4  [(sansei, JJ), (male, NN), (born, VBN), (march...  \n",
            "\n",
            "Example sentence:\n",
            "nisei female born may selleck washington spent much childhood beaverton oregon father owned farm influenced early age parent conversion christianity world war ii removed portland assembly center oregon minidoka concentration camp idaho war worked establish successful volunteer program feed homeless seattle washington\n",
            "\n",
            "Dependency Parsing:\n",
            "nisei -> amod (female)\n",
            "female -> nsubj (selleck)\n",
            "born -> acl (female)\n",
            "may -> aux (selleck)\n",
            "selleck -> compound (washington)\n",
            "washington -> nsubj (spent)\n",
            "spent -> ROOT (spent)\n",
            "much -> amod (beaverton)\n",
            "childhood -> compound (beaverton)\n",
            "beaverton -> nmod (farm)\n",
            "oregon -> compound (father)\n",
            "father -> npadvmod (owned)\n",
            "owned -> amod (farm)\n",
            "farm -> nsubj (influenced)\n",
            "influenced -> ccomp (spent)\n",
            "early -> amod (conversion)\n",
            "age -> compound (parent)\n",
            "parent -> compound (conversion)\n",
            "conversion -> compound (ii)\n",
            "christianity -> compound (ii)\n",
            "world -> compound (ii)\n",
            "war -> compound (ii)\n",
            "ii -> nsubj (removed)\n",
            "removed -> conj (spent)\n",
            "portland -> compound (center)\n",
            "assembly -> compound (center)\n",
            "center -> compound (camp)\n",
            "oregon -> compound (concentration)\n",
            "minidoka -> compound (concentration)\n",
            "concentration -> compound (camp)\n",
            "camp -> compound (war)\n",
            "idaho -> compound (war)\n",
            "war -> nsubj (establish)\n",
            "worked -> acl (war)\n",
            "establish -> ccomp (removed)\n",
            "successful -> amod (feed)\n",
            "volunteer -> compound (program)\n",
            "program -> compound (feed)\n",
            "feed -> dobj (establish)\n",
            "homeless -> compound (seattle)\n",
            "seattle -> npadvmod (establish)\n",
            "washington -> npadvmod (establish)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1afffae76980460bb7a12bb9fa8fdf96-0\" class=\"displacy\" width=\"7400\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">nisei</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">female</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">born</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">may</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">selleck</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">washington</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">spent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">much</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">childhood</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">beaverton</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">oregon</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">father</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">owned</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">farm</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">influenced</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">early</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">age</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">parent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">conversion</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">christianity</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">world</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">war</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">ii</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">removed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">portland</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">assembly</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">center</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">oregon</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">minidoka</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">concentration</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">camp</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">idaho</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">war</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">worked</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">establish</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">successful</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">volunteer</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">program</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">feed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">homeless</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7050\">seattle</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7050\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7225\">washington</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,264.5 735.0,264.5 735.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-2\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M380.0,441.5 L388.0,429.5 372.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-5\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,264.5 1610.0,264.5 1610.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,264.5 2310.0,264.5 2310.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-10\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,441.5 L1987,429.5 2003,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-11\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-13\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,177.0 2490.0,177.0 2490.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2490.0,441.5 L2498.0,429.5 2482.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-14\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,264.5 3185.0,264.5 3185.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-15\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,441.5 L2862,429.5 2878,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-16\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,352.0 3180.0,352.0 3180.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,441.5 L3037,429.5 3053,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-17\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,89.5 3895.0,89.5 3895.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,441.5 L3212,429.5 3228,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-18\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,177.0 3890.0,177.0 3890.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,441.5 L3387,429.5 3403,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-19\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,264.5 3885.0,264.5 3885.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-20\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,441.5 L3737,429.5 3753,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-21\" stroke-width=\"2px\" d=\"M3920,439.5 C3920,352.0 4055.0,352.0 4055.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3920,441.5 L3912,429.5 3928,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-22\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,2.0 4075.0,2.0 4075.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4075.0,441.5 L4083.0,429.5 4067.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-23\" stroke-width=\"2px\" d=\"M4270,439.5 C4270,264.5 4585.0,264.5 4585.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4270,441.5 L4262,429.5 4278,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-24\" stroke-width=\"2px\" d=\"M4445,439.5 C4445,352.0 4580.0,352.0 4580.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4445,441.5 L4437,429.5 4453,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-25\" stroke-width=\"2px\" d=\"M4620,439.5 C4620,177.0 5290.0,177.0 5290.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4620,441.5 L4612,429.5 4628,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-26\" stroke-width=\"2px\" d=\"M4795,439.5 C4795,264.5 5110.0,264.5 5110.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4795,441.5 L4787,429.5 4803,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-27\" stroke-width=\"2px\" d=\"M4970,439.5 C4970,352.0 5105.0,352.0 5105.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,441.5 L4962,429.5 4978,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-28\" stroke-width=\"2px\" d=\"M5145,439.5 C5145,352.0 5280.0,352.0 5280.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,441.5 L5137,429.5 5153,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-29\" stroke-width=\"2px\" d=\"M5320,439.5 C5320,264.5 5635.0,264.5 5635.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5320,441.5 L5312,429.5 5328,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-30\" stroke-width=\"2px\" d=\"M5495,439.5 C5495,352.0 5630.0,352.0 5630.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5495,441.5 L5487,429.5 5503,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-31\" stroke-width=\"2px\" d=\"M5670,439.5 C5670,264.5 5985.0,264.5 5985.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,441.5 L5662,429.5 5678,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-32\" stroke-width=\"2px\" d=\"M5670,439.5 C5670,352.0 5805.0,352.0 5805.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5805.0,441.5 L5813.0,429.5 5797.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-33\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,89.5 5995.0,89.5 5995.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5995.0,441.5 L6003.0,429.5 5987.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-34\" stroke-width=\"2px\" d=\"M6195,439.5 C6195,264.5 6685.0,264.5 6685.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6195,441.5 L6187,429.5 6203,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-35\" stroke-width=\"2px\" d=\"M6370,439.5 C6370,352.0 6505.0,352.0 6505.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6370,441.5 L6362,429.5 6378,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-36\" stroke-width=\"2px\" d=\"M6545,439.5 C6545,352.0 6680.0,352.0 6680.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6545,441.5 L6537,429.5 6553,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-37\" stroke-width=\"2px\" d=\"M6020,439.5 C6020,177.0 6690.0,177.0 6690.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6690.0,441.5 L6698.0,429.5 6682.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-38\" stroke-width=\"2px\" d=\"M6895,439.5 C6895,352.0 7030.0,352.0 7030.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6895,441.5 L6887,429.5 6903,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-39\" stroke-width=\"2px\" d=\"M6020,439.5 C6020,89.5 7045.0,89.5 7045.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7045.0,441.5 L7053.0,429.5 7037.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1afffae76980460bb7a12bb9fa8fdf96-0-40\" stroke-width=\"2px\" d=\"M6020,439.5 C6020,2.0 7225.0,2.0 7225.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1afffae76980460bb7a12bb9fa8fdf96-0-40\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7225.0,441.5 L7233.0,429.5 7217.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Named Entity Recognition Results:\n",
            "GPE: 4126\n",
            "PERSON: 726\n",
            "DATE: 969\n",
            "NORP: 574\n",
            "ORG: 1078\n",
            "CARDINAL: 135\n",
            "LOC: 139\n",
            "EVENT: 634\n",
            "LAW: 2\n",
            "ORDINAL: 64\n",
            "LANGUAGE: 9\n",
            "FAC: 30\n",
            "TIME: 8\n",
            "MONEY: 3\n",
            "QUANTITY: 2\n",
            "PRODUCT: 4\n",
            "Named entities extracted and saved to narrators_with_entities.csv\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "\n",
        "!pip install -q spacy\n",
        "!pip install -q nltk\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "# (1) Parts of Speech (POS) Tagging:\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Loading spacy's english language model\n",
        "\n",
        "df = pd.read_csv('narrators_cleaned.csv')\n",
        "\n",
        "def pos_tagging(text):\n",
        "  if isinstance(text, str):\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "    # count nouns ('NN'), Verbs (VB), Adjectives (JJ), and Adverbs (RB)\n",
        "    pos_counts = Counter(tag for word, tag in pos_tags) # frequency count for each pos tag.\n",
        "\n",
        "    noun_count = pos_counts['NN'] + pos_counts['NNS']  # singular and plural nouns\n",
        "    verb_count = (pos_counts['VB'] + pos_counts['VBD'] + pos_counts['VBG'] +  #verb count (base, past, gerund, past participle, present, and third person singular)\n",
        "                  pos_counts['VBN'] + pos_counts['VBP'] + pos_counts['VBZ'])\n",
        "    adj_count = pos_counts['JJ'] + pos_counts['JJR'] + pos_counts['JJS']  # adjective count\n",
        "    adv_count = pos_counts['RB'] + pos_counts['RBR'] + pos_counts['RBS']  # adverb count\n",
        "\n",
        "    return noun_count, verb_count, adj_count, adv_count, pos_tags\n",
        "\n",
        "  else:\n",
        "    return 0, 0, 0, 0, []\n",
        "\n",
        "# Apply POS tagging and calculate the counts\n",
        "df['POS_Tags'] = df['Txt_Lemm'].apply(lambda x: pos_tagging(x))\n",
        "\n",
        "# Create new columns for results\n",
        "df['Nouns'], df['Verbs'], df['Adjectives'], df['Adverbs'], df['POS_Tagged'] = zip(*df['POS_Tags'])\n",
        "\n",
        "# Show the results\n",
        "print(\"\\nPOS Tagging Results:\")\n",
        "print(df[['Nouns', 'Verbs', 'Adjectives', 'Adverbs', 'POS_Tagged']].head())\n",
        "\n",
        "# (2) Constituency Parsing and Dependency Parsing:\n",
        "# Print out the constituency parsing trees and dependency parsing trees of all the sentences.\n",
        "# Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "# Using the first sentence as an example:\n",
        "example_text = df['Txt_Lemm'].iloc[0]     # selects the cleaned and lemmatized text\n",
        "\n",
        "def parse_example_sentences(text):\n",
        "  doc = nlp(text)                         # passes the text to spacy\n",
        "\n",
        "  # Dependency parsing\n",
        "  print(\"\\nDependency Parsing:\")\n",
        "  for token in doc:\n",
        "    print(f\"{token.text} -> {token.dep_} ({token.head.text})\")\n",
        "\n",
        "  # Display parsing tree for the first sentence\n",
        "  displacy.render(doc, style='dep', jupyter=True)  # Render dependency tree in Jupyter\n",
        "\n",
        "print(f\"\\nExample sentence:\\n{example_text}\")\n",
        "parse_example_sentences(example_text)\n",
        "\n",
        "# (3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names,\n",
        "# and date from the clean texts, calculate the count of each entity.\n",
        "\n",
        "def extract_named_entities(text):\n",
        "  if isinstance(text, str):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "# Apply Named Entity Recognition\n",
        "df['Named_Entities'] = df['Txt_Lemm'].apply(extract_named_entities)\n",
        "\n",
        "# Now count the frequency of each type of entity\n",
        "def count_entities(entities):\n",
        "  # Extract only the entity labels (e.g., 'PERSON', 'ORG', 'GPE', 'DATE', etc.)\n",
        "  entity_labels = [label for _, label in entities]\n",
        "  entity_counts = Counter(entity_labels)\n",
        "  return entity_counts\n",
        "\n",
        "# Apply the entity counting function to the 'Named_Entities' column\n",
        "df['Entity_Counts'] = df['Named_Entities'].apply(count_entities)\n",
        "\n",
        "# Now let's aggregate the entity counts across the entire dataset\n",
        "total_entity_counts = Counter()\n",
        "for entity_count in df['Entity_Counts']:\n",
        "  total_entity_counts.update(entity_count)\n",
        "\n",
        "# Display the counts of entities such as person names, organizations, locations, and dates\n",
        "print(\"\\nNamed Entity Recognition Results:\")\n",
        "for entity_type, count in total_entity_counts.items():\n",
        "  print(f\"{entity_type}: {count}\")\n",
        "\n",
        "# Save the updated dataframe with named entities to a new CSV\n",
        "df.to_csv('narrators_with_entities.csv', index=False)\n",
        "print(\"Named entities extracted and saved to narrators_with_entities.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comment**\n",
        "Make sure to submit the cleaned data CSV in the comment section - 10 points"
      ],
      "metadata": {
        "id": "CXNn1lEVbMsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I submitted three CSV files on GitHub.\n",
        "  # 1. narrators.csv\n",
        "  # 2. narrators_cleaned.csv\n",
        "  # 3. narrators_with_entities.csv"
      ],
      "metadata": {
        "id": "qYRO5Cn8bYwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your response below\n",
        "\"\"\"\n",
        "Question 1 stumped me for a long time.\n",
        "  I spent hours trying option (2) to scrape IMDB for 1,000 reviews of the movie Wolfs.\n",
        "\n",
        "  I inspected the webpage and successfully identified the HTML class for all reviews. However, the class was only accessible\n",
        "after clicking on an \"All\" button. No matter what I tried I couldn't get the script to click the \"All\" button and then\n",
        "scrape reviews. It failed continuously.\n",
        "\n",
        "  Furthermore, the URL was the same before and after clicking the \"All\" button, so I couldn't change my base URL. I felt like\n",
        "I was very close, but I couldn't get it to actually pull html data. My research indicated that the page was actually built on\n",
        "Javascript so I tried Selenium. I've used Selenium successfully in the past, but this also resulted in a lack of data.\n",
        "\n",
        "  Through all this, I continuously received a status code of 200 which means my request to the server was successful, yet\n",
        "there was no data.\n",
        "\n",
        "  I finally decided to start over and attempt option (5) to scrape the DDR for all narrators. This was straightforward. I\n",
        "folowed Ms. Fengjiao's example from class to impliment a similar solution. I nested a for loop iterating through\n",
        "\n",
        "Question 2 was much easier.\n",
        "  The data cleaning requirements were explained in class well. I quickly implemented techniques from class and a Udemy\n",
        "course I've been taking. This didn't take long. Each iteration resulted in an improved version of the last. I chose to base\n",
        "\n",
        "\n",
        "Question 3 was also hard.\n",
        "  I start by applying Part of Speech (POS) tagging to identify nouns, verbs, adjectives, and adverbs in the text data and\n",
        "calculating their total counts. Next, it uses SpaCy for Dependency Parsing to analyze the structure of sentences and display\n",
        "the parsing tree for the first sentence in the dataset. I actually did this for all sentences at first and nearly crashed the\n",
        "kernel.\n",
        "  Lastly, I used Named Entity Recognition (NER) to extract entities such as person names, locations, and dates, and then\n",
        "count the frequency of each entity type across the entire dataset. The results, including POS tags and named entities, are\n",
        "saved to a CSV file for further analysis.\n",
        "\n",
        "Feedback regarding the allotted time for assignment:\n",
        "  The amount of time to complete the assignment was adequate. I planned on submitting the assignment until I saw there was an\n",
        "extension. I chose to use the extension to clean up my code and add additional comments.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_e557s2w4BpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "044c030e-cdc4-463d-b9b6-397ce6899616"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQuestion 1 stumped me for a long time. \\n  I spent hours trying option (2) to scrape IMDB for 1,000 reviews of the movie Wolfs.\\n\\n  I inspected the webpage and successfully identified the HTML class for all reviews. However, the class was only accessible \\nafter clicking on an \"All\" button. No matter what I tried I couldn\\'t get the script to click the \"All\" button and then \\nscrape reviews. It failed continuously.\\n\\n  Furthermore, the URL was the same before and after clicking the \"All\" button, so I couldn\\'t change my base URL. I felt like\\nI was very close, but I couldn\\'t get it to actually pull html data. My research indicated that the page was actually built on\\nJavascript so I tried Selenium. I\\'ve used Selenium successfully in the past, but this also resulted in a lack of data.\\n\\n  Through all this, I continuously received a status code of 200 which means my request to the server was successful, yet \\nthere was no data.\\n\\n  I finally decided to start over and attempt option (5) to scrape the DDR for all narrators. This was straightforward. I\\nfolowed Ms. Fengjiao\\'s example from class to impliment a similar solution. I nested a for loop iterating through \\n\\nQuestion 2 was much easier. \\n  The data cleaning requirements were explained in class well. I quickly implemented techniques from class and a Udemy\\ncourse I\\'ve been taking. This didn\\'t take long. Each iteration resulted in an improved version of the last. I chose to base\\n\\n\\nQuestion 3 was also hard. \\n  I start by applying Part of Speech (POS) tagging to identify nouns, verbs, adjectives, and adverbs in the text data and\\ncalculating their total counts. Next, it uses SpaCy for Dependency Parsing to analyze the structure of sentences and display \\nthe parsing tree for the first sentence in the dataset. I actually did this for all sentences at first and nearly crashed the \\nkernel. \\n  Lastly, I used Named Entity Recognition (NER) to extract entities such as person names, locations, and dates, and then \\ncount the frequency of each entity type across the entire dataset. The results, including POS tags and named entities, are \\nsaved to a CSV file for further analysis.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}